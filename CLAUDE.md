# Claude Code Project Context

## Project Overview
Analyse de l'alb√©do du glacier Athabasca utilisant les donn√©es MODIS et Google Earth Engine.
Impl√©mentation de la m√©thodologie de Williamson & Menounos (2021) pour l'analyse hypsom√©trique.

## Key Commands

### Testing & Validation
```bash
# Run main analysis
python simple_main.py

# Check code quality
python -m pylint src/
python -m flake8 src/
```

### Dependencies
```bash
pip install -r requirements.txt
```

## Project Structure
- `src/`: Code source principal
  - `analysis/`: Modules d'analyse statistique et hypsom√©trique
  - `data/`: Extraction de donn√©es GEE
  - `visualization/`: Cr√©ation de graphiques et cartes
  - `workflows/`: Flux de travail complets
- `outputs/`: R√©sultats CSV
- `figures/`: Graphiques g√©n√©r√©s
- `maps/`: Cartes interactives HTML

## Key Technical Details

### MODIS Data Products

#### MOD10A1/MYD10A1 (Daily Snow Albedo)
- Collections: MODIS/061/MOD10A1 (Terra), MODIS/061/MYD10A1 (Aqua)
- R√©solution: 500m
- Bande principale: Snow_Albedo_Daily_Tile
- Bande qualit√©: NDSI_Snow_Cover_Basic_QA
- Filtre qualit√©: QA = 0 uniquement (best quality)
- Plage valide: 5-99 (avant mise √† l'√©chelle)
- Facteur d'√©chelle: 0.01
- Usage: Analyse quotidienne de l'alb√©do de neige
- **üìö Documentation de r√©f√©rence**:
  - Guide utilisateur officiel: `docs/mod10a1-user-guide.md`
  - R√©f√©rence des flags QA: `docs/mod10a1-qa-flags.md`
  - Techniques de gap-filling: `docs/modis-gap-filling-interpolation.md` ‚ö†Ô∏è *Exemples en JavaScript*

#### MCD43A3 (Daily Broadband Albedo - 16-day moving window)
- Collection: MODIS/061/MCD43A3
- R√©solution: 500m
- **R√©solution temporelle**: DAILY product (not 16-day composite!)
  - Utilise une fen√™tre mobile de 16 jours centr√©e sur chaque jour
  - La date du produit = centre de la fen√™tre (9e jour)
  - Pond√©ration temporelle vers le jour central
  - Fournit des valeurs d'alb√©do quotidiennes avec robustesse statistique
- Bandes spectrales:
  - Albedo_BSA_Band1-4 (bandes spectrales individuelles)
  - Albedo_BSA_vis (alb√©do visible large bande)
  - Albedo_BSA_nir (alb√©do proche infrarouge)
  - Albedo_BSA_shortwave (alb√©do courtes longueurs d'onde)
- Bandes qualit√©: BRDF_Albedo_Band_Mandatory_Quality_*
- Filtre qualit√©: QA = 0 uniquement (full BRDF inversions)
- Facteur d'√©chelle: 0.001
- Usage: Analyse spectrale quotidienne suivant Williamson & Menounos (2021)

### Quality Filtering Standards
- **Approche stricte**: QA = 0 uniquement pour tous les produits
- **Pixels minimum**: ‚â• 5 pixels valides par observation
- **Plage alb√©do valide**: 0.0 - 1.0 apr√®s mise √† l'√©chelle
- **P√©riode de fonte**: Juin-Septembre uniquement

### MOD10A1 QA Flags Interpretation
- **NDSI_Snow_Cover_Basic_QA**: 0=best, 1=good, 2=ok
- **NDSI_Snow_Cover_Algorithm_Flags_QA**: Bit flags pour screens sp√©cifiques
  - Bit 0: Inland water
  - Bit 1: Low visible reflectance 
  - Bit 2: Low NDSI
  - Bit 3: Temperature/height screen
  - Bit 4: High SWIR reflectance
  - Bit 5-6: Cloud confidence
  - Bit 7: Low illumination
- **R√©f√©rence compl√®te**: Voir `docs/mod10a1-qa-flags.md` pour d√©tails

### Advanced QA Filtering (Nouveau)
- **Fonction standard**: `mask_modis_snow_albedo_fast()` (Basic QA ‚â§ 1)
- **Fonction avanc√©e**: `mask_modis_snow_albedo_advanced()` avec Algorithm flags
- **Niveaux de qualit√©**:
  - `strict`: Basic QA = 0, tous algorithm flags filtr√©s
  - `standard`: Basic QA ‚â§ 1, flags critiques filtr√©s (recommand√©)
  - `relaxed`: Basic QA ‚â§ 2, filtrage minimal
- **Usage dans workflows**:
  ```python
  run_melt_season_analysis_williamson(
      use_advanced_qa=True,    # Active le filtrage avanc√©
      qa_level='standard'      # Niveau de qualit√©
  )
  ```
- **Avantages**: Meilleure robustesse statistique, conformit√© Williamson & Menounos (2021)

### QA Tracking System (Nouveau)
- **Filenames avec QA**: Les fichiers de sortie incluent automatiquement les param√®tres QA
  - Format: `athabasca_melt_season_data_advanced_standard.csv`
  - Format: `athabasca_melt_season_results_basic_relaxed.csv`
- **Colonnes QA dans les donn√©es**:
  - `qa_advanced`: Boolean (True/False)
  - `qa_level`: String ('strict', 'standard', 'relaxed')  
  - `qa_description`: String lisible ("Advanced QA, standard level")
- **Auto-d√©tection**: Le syst√®me trouve automatiquement les fichiers QA les plus r√©cents
- **Tra√ßabilit√©**: Chaque analyse peut √™tre reproduite avec les m√™mes param√®tres QA
- **Exemple de filenames**:
  - `athabasca_melt_season_data_advanced_standard.csv` - Donn√©es avec Advanced QA, niveau standard
  - `athabasca_melt_season_results_basic_strict.csv` - R√©sultats avec Basic QA, niveau strict

### Analyse Hypsom√©trique
- Bandes d'√©l√©vation: ¬±100m autour de l'√©l√©vation m√©diane
- DEM: SRTM clipp√© avec le masque du glacier
- Tests statistiques: Mann-Kendall et pente de Sen

### Important Files
- `config.py`: ROI du glacier Athabasca
- `paths.py`: Gestion des chemins de fichiers
- `simple_main.py`: Point d'entr√©e principal

## Common Issues & Solutions

### DEM Masking
Le DEM doit √™tre clipp√© avec `athabasca_roi` avant utilisation:
```python
srtm_clipped = srtm.clip(athabasca_roi)
```

### Memory Management
Extraction ann√©e par ann√©e pour √©viter les timeouts GEE.

## Data Processing Workflows

### Extraction de donn√©es
1. **MOD10A1/MYD10A1**: Extraction ann√©e par ann√©e via `extract_melt_season_data_yearly()`
2. **MCD43A3**: Extraction via `extract_mcd43a3_data()` dans `broadband_albedo.py`
3. **Fusion**: Les donn√©es Terra et Aqua sont fusionn√©es pour MOD10A1/MYD10A1

### Analyses principales
1. **Tendances temporelles**: Analyse des changements d'alb√©do sur la p√©riode d'√©tude
2. **Analyse hypsom√©trique**: Variation de l'alb√©do selon l'√©l√©vation (Williamson & Menounos 2021)
3. **Analyse spectrale**: Comparaison visible vs NIR pour d√©tecter la contamination
4. **Statistiques saisonni√®res**: Focus sur la p√©riode de fonte (juin-septembre)

## Data Processing Techniques

### Gap-Filling and Interpolation
- **Probl√®me**: Donn√©es MODIS manquantes dues aux nuages, ombres, etc.
- **Solutions disponibles**: 
  - Interpolation temporelle
  - Moyennes mobiles
  - Fusion multi-capteurs (Terra + Aqua)
- **‚ö†Ô∏è Note importante**: Le document `docs/modis-gap-filling-interpolation.md` contient des exemples en **JavaScript (Google Earth Engine)**. Pour l'impl√©mentation Python, adapter la syntaxe en utilisant:
  - `ee.ImageCollection` au lieu de `ee.ImageCollection()`
  - M√©thodes Python √©quivalentes pour les fonctions JavaScript
  - Attention aux diff√©rences de syntaxe pour les callbacks et lambdas

## Recent Updates
- Harmonisation des filtres qualit√© MCD43A3 avec MOD10A1 (QA = 0 uniquement)
- Correction du clipping DEM avec le masque du glacier
- Ajout des donn√©es annuelles dans les r√©sultats hypsom√©triques
- Am√©lioration de la visualisation des bandes d'√©l√©vation
- Clarification: MCD43A3 est un produit QUOTIDIEN (fen√™tre mobile 16 jours)
- **QA Tracking System**: Filenames and data now include QA settings for reproducibility

## Code Organization Guidelines

### File Length Management
- **Maximum file length**: Garder les fichiers Python sous 500 lignes si possible
- **Diviser les longs fichiers**: Quand un fichier d√©passe 500-700 lignes, refactoriser en modules
- **Structure modulaire**: S√©parer les responsabilit√©s en modules logiques:
  - Extraction/traitement de donn√©es
  - Fonctions d'analyse
  - Visualisation/graphiques
  - Orchestration du workflow principal

### Strat√©gie de Refactorisation
- **Exemple 1**: `broadband_albedo.py` (1000+ lignes) divis√© en:
  - `src/data/mcd43a3_extraction.py` - Fonctions d'extraction
  - `src/analysis/spectral_analysis.py` - M√©thodes d'analyse
  - `src/visualization/spectral_plots.py` - Fonctions de visualisation
  - `src/workflows/broadband_albedo.py` - Workflow principal (~200 lignes)

- **Exemple 2**: `spectral_plots.py` (967 lignes) divis√© en:
  - `src/visualization/static_plots.py` (604 lignes) - Graphiques matplotlib
  - `src/visualization/interactive_plots.py` (369 lignes) - Tableaux de bord plotly
  - `src/visualization/spectral_plots.py` (26 lignes) - Interface principale
  
### Avantages de cette approche:
- ‚úÖ Fichiers maintenables et lisibles
- ‚úÖ S√©paration claire des responsabilit√©s
- ‚úÖ Backwards compatibility des imports
- ‚úÖ Possibilit√© d'extension future
- **B√©n√©fices**: Meilleure maintenabilit√©, r√©utilisabilit√© et tests

### Principes de Code
- Un fichier = une responsabilit√© claire
- Imports explicites entre modules
- Documentation des interfaces entre modules
- Tests unitaires plus faciles avec des modules courts

## Critical Bug Fixes & Solutions

### ‚ö†Ô∏è STREAMLIT APP CRASHES - INFINITE RECURSION BUG (SOLVED)

**Problem**: Streamlit app was dying silently during data processing at ~65% completion (CSV export phase).

**Root Cause**: Infinite recursion caused by dangerous monkey-patching of pandas DataFrame.to_csv()

```python
# DEADLY CODE (NEVER DO THIS):
pd.DataFrame.to_csv = safe_to_csv  # Monkey patch

def safe_to_csv(self, path_or_buf=None, **kwargs):
    return safe_csv_write(self, str(path_or_buf), ...)

def safe_csv_write(df, file_path, ...):
    df.to_csv(temp_file, ...)  # <-- CALLS MONKEY-PATCHED VERSION = INFINITE RECURSION!
```

**Death Cycle**:
1. `safe_csv_write()` called
2. Calls `df.to_csv()` 
3. Monkey patch redirects back to `safe_csv_write()` 
4. **INFINITE RECURSION**
5. Stack overflow in pandas C extension
6. **SILENT PROCESS DEATH** (no Python exception)
7. Streamlit loses connection ‚Üí apparent "crash"

**‚úÖ SOLUTION**: 
- **NEVER monkey-patch pandas methods** in workflows
- Use direct calls to original pandas methods:
```python
# SAFE CODE:
import pandas as pd
original_to_csv = pd.DataFrame.to_csv
original_to_csv(df, file_path, index=False, encoding='utf-8')
```

**Files Fixed**:
- `src/workflows/melt_season.py`: Removed monkey patching, fixed fallback functions
- `src/utils/file_utils.py`: Added explicit original method calls
- `streamlit_app/src/utils/processing_manager.py`: Enhanced error handling

**Result**: Streamlit app now completes full workflow without crashes ‚úÖ

### File Permission Issues on Windows (SOLVED)

**Problem**: Windows file locking issues with CSV exports

**Solutions Applied**:
1. **Atomic file operations**: Write to `.tmp` files, then rename
2. **Retry mechanisms**: Multiple attempts with backoff
3. **Safe path resolution**: Cross-platform path normalization
4. **Backup/restore**: Safe file replacement on Windows

**Implementation**: `src/utils/file_utils.py` - `safe_csv_write()` function

### Import Path Issues in Streamlit Context (SOLVED)

**Problem**: Different import paths when running from Streamlit vs direct execution

**Solution**: Fallback import strategy with inline function definitions
```python
try:
    from utils.file_utils import safe_csv_write
except ImportError:
    try:
        from src.utils.file_utils import safe_csv_write
    except ImportError:
        # Inline fallback definitions
        def safe_csv_write(...): ...
```

## Debugging Guidelines

### When Streamlit App Crashes/Dies:
1. **Check for infinite recursion** - especially in monkey-patched methods
2. **Look for silent C extension crashes** - no Python traceback
3. **Monitor memory usage** - but crashes can happen with low memory too
4. **Add progress tracking** - identify exact failure point
5. **Use threading timeouts** - detect infinite hangs

### Warning Signs:
- Process dies at exact same point repeatedly
- No Python exception/traceback shown
- "Connection lost" or similar Streamlit messages
- High CPU usage with no progress

### Prevention:
- ‚ùå Never monkey-patch pandas/numpy methods
- ‚úÖ Use explicit method references: `pd.DataFrame.to_csv(df, path)`
- ‚úÖ Add comprehensive error handling in workflows
- ‚úÖ Use timeouts for potentially hanging operations
- ‚úÖ Test with small datasets first