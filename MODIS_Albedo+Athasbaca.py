import ee
import geemap
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import folium
import json
from scipy.interpolate import UnivariateSpline
from scipy.signal import savgol_filter

# Initialiser Earth Engine
# ee.Authenticate()  # Ex√©cuter une seule fois
ee.Initialize()

# ================================================================================
# CONFIGURATION OPTIMIS√âE
# ================================================================================

# IMPORTANT: Utilisation des collections MODIS Version 6.1 (061)
# Les collections Version 6 (006) sont d√©pr√©ci√©es depuis 2023
# Nouvelles collections:
# - MODIS/061/MOD10A1 (Terra Snow Cover)
# - MODIS/061/MYD10A1 (Aqua Snow Cover) 
# - MODIS/061/MCD43A3 (Combined BRDF/Albedo)

# Charger le masque GeoJSON pr√©cis du glacier Athabasca
with open('Athabasca_mask_2023 (1).geojson', 'r') as f:
    athabasca_geojson = json.load(f)

# Convertir le GeoJSON en geometry Earth Engine
# Le GeoJSON contient plusieurs features, on les combine
geometries = []
for feature in athabasca_geojson['features']:
    if feature['geometry']['type'] == 'MultiPolygon':
        for polygon in feature['geometry']['coordinates']:
            geometries.append(ee.Geometry.Polygon(polygon))
    elif feature['geometry']['type'] == 'Polygon':
        geometries.append(ee.Geometry.Polygon(feature['geometry']['coordinates']))

# Cr√©er une collection de geometries et les unir
athabasca_roi = ee.FeatureCollection(geometries).geometry()

# Coordonn√©es pour la zone de visualisation (bounding box approximative)
ATHABASCA_BOUNDS = [
    [-117.32, 52.15],  # SW
    [-117.22, 52.15],  # SE  
    [-117.22, 52.22],  # NE
    [-117.32, 52.22],  # NW
    [-117.32, 52.15]   # Fermer polygone
]

# Station m√©t√©o sur le glacier
ATHABASCA_STATION = [-117.245, 52.214]
station_point = ee.Geometry.Point(ATHABASCA_STATION)

# ================================================================================
# PARAM√àTRES D'OPTIMISATION
# ================================================================================

# Option 1: P√©riode r√©duite (derni√®res ann√©es + ann√©es feux)
PERIODS_RAPIDE = {
    'recent': ('2020-01-01', '2024-10-31'),  # 5 ans r√©cents jusqu'√† automne 2024
    'fire_years': ('2017-01-01', '2021-12-31'),  # Ann√©es feux + context
    'decade': ('2015-01-01', '2024-10-31'),  # Derni√®re d√©cennie
    'sample': ('2010-01-01', '2024-10-31'),  # 15 ans avec √©chantillonnage
    'full_recent': ('2019-01-01', '2024-10-31')  # 6 ans pour mieux voir les tendances
}

# Option 2: √âchantillonnage temporel
SAMPLING_OPTIONS = {
    'weekly': 7,      # Une image par semaine
    'monthly': 30,    # Une image par mois
    'seasonal': 90    # Une image par saison
}

# Option 3: R√©solution spatiale r√©duite
SCALE_OPTIONS = {
    'fine': 250,      # R√©solution native MODIS (lent)
    'medium': 500,    # Compromis (recommand√©)
    'coarse': 1000    # Rapide pour tests
}

print("üèîÔ∏è Configuration Optimis√©e Glacier Athabasca")

# Calculer et afficher la surface du glacier
glacier_area = athabasca_roi.area().divide(1e6).getInfo()  # Convertir en km¬≤
print(f"üìè Surface du glacier (masque pr√©cis): {glacier_area:.2f} km¬≤")

# ================================================================================
# FONCTIONS DE MASQUAGE SIMPLIFI√âES
# ================================================================================

def mask_modis_snow_albedo_fast(image):
    """Version simplifi√©e du masquage pour vitesse"""
    # S√©lection rapide - moins de contr√¥les qualit√©
    albedo = image.select('Snow_Albedo_Daily_Tile')
    qa = image.select('NDSI_Snow_Cover_Basic_QA')
    
    # Masque basique
    valid_albedo = albedo.gte(5).And(albedo.lte(99))
    good_quality = qa.eq(0)  # Seulement meilleure qualit√©
    
    # Facteur √©chelle
    scaled = albedo.multiply(0.01).updateMask(valid_albedo.And(good_quality))
    
    return scaled.rename('albedo_daily').copyProperties(image, ['system:time_start'])

def mask_modis_broadband_albedo_fast(image):
    """Version simplifi√©e alb√©do large bande"""
    vis_albedo = image.select('Albedo_WSA_vis')
    nir_albedo = image.select('Albedo_WSA_nir')
    qa = image.select('BRDF_Albedo_Quality')
    
    # Masque simplifi√©
    good_quality = qa.lte(1)
    valid_vis = vis_albedo.gte(0).And(vis_albedo.lte(1000))
    valid_nir = nir_albedo.gte(0).And(nir_albedo.lte(1000))
    
    # Facteur √©chelle et calcul
    vis_scaled = vis_albedo.multiply(0.001).updateMask(good_quality.And(valid_vis))
    nir_scaled = nir_albedo.multiply(0.001).updateMask(good_quality.And(valid_nir))
    broadband = vis_scaled.multiply(0.7).add(nir_scaled.multiply(0.3))
    
    return broadband.rename('albedo_broadband').copyProperties(image, ['system:time_start'])

# ================================================================================
# EXTRACTION SIMPLIFI√âE
# ================================================================================

def extract_time_series_fast(start_date, end_date, 
                            use_broadband=False,
                            sampling_days=None,
                            scale=500):
    """
    Version simplifi√©e - statistiques pour le glacier entier sans division par zones
    """
    print(f"‚ö° Extraction RAPIDE {start_date} √† {end_date}")
    print(f"   √âchantillonnage: {sampling_days} jours, R√©solution: {scale}m")
    
    # Choisir collection et fonction masquage
    if use_broadband:
        collection = ee.ImageCollection('MODIS/061/MCD43A3') \
            .filterBounds(athabasca_roi) \
            .filterDate(start_date, end_date) \
            .map(mask_modis_broadband_albedo_fast)
        albedo_band = 'albedo_broadband'
    else:
        # Combiner MOD10A1 et MYD10A1 (Version 6.1)
        mod_col = ee.ImageCollection('MODIS/061/MOD10A1') \
            .filterBounds(athabasca_roi) \
            .filterDate(start_date, end_date) \
            .map(mask_modis_snow_albedo_fast)
        
        myd_col = ee.ImageCollection('MODIS/061/MYD10A1') \
            .filterBounds(athabasca_roi) \
            .filterDate(start_date, end_date) \
            .map(mask_modis_snow_albedo_fast)
        
        collection = mod_col.merge(myd_col).sort('system:time_start')
        albedo_band = 'albedo_daily'
    
    # √âchantillonnage temporel si sp√©cifi√©
    if sampling_days:
        # Prendre seulement certaines images pour r√©duire la charge
        collection = collection.filterMetadata('system:index', 'not_equals', '') \
            .limit(1000)  # Limite pour √©viter timeout
    
    print(f"üì° Images √† traiter: {collection.size().getInfo()}")
    
    def calculate_simple_stats(image):
        """Calculs simplifi√©s - glacier entier seulement"""
        albedo = image.select(albedo_band)
        
        # Stats glacier complet avec plusieurs m√©triques
        stats = albedo.reduceRegion(
            reducer=ee.Reducer.mean().combine(
                reducer2=ee.Reducer.stdDev(),
                sharedInputs=True
            ).combine(
                reducer2=ee.Reducer.min(),
                sharedInputs=True
            ).combine(
                reducer2=ee.Reducer.max(),
                sharedInputs=True
            ).combine(
                reducer2=ee.Reducer.count(),
                sharedInputs=True
            ),
            geometry=athabasca_roi,
            scale=scale,
            maxPixels=1e9
        )
        
        return ee.Feature(None, {
            'date': image.date().format('YYYY-MM-dd'),
            'timestamp': image.date().millis(),
            'albedo_mean': stats.get(f'{albedo_band}_mean'),
            'albedo_stdDev': stats.get(f'{albedo_band}_stdDev'),
            'albedo_min': stats.get(f'{albedo_band}_min'),
            'albedo_max': stats.get(f'{albedo_band}_max'),
            'pixel_count': stats.get(f'{albedo_band}_count')
        })
    
    # Traitement collection
    time_series = collection.map(calculate_simple_stats)
    
    # Conversion DataFrame
    try:
        data_list = time_series.getInfo()['features']
        records = [f['properties'] for f in data_list if f['properties'].get('albedo_mean')]
        
        df = pd.DataFrame(records)
        if not df.empty:
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date').reset_index(drop=True)
            
            # Colonnes temporelles
            df['year'] = df['date'].dt.year
            df['month'] = df['date'].dt.month
            df['season'] = df['month'].map({
                12: 'Hiver', 1: 'Hiver', 2: 'Hiver',
                3: 'Printemps', 4: 'Printemps', 5: 'Printemps',
                6: '√ât√©', 7: '√ât√©', 8: '√ât√©',
                9: 'Automne', 10: 'Automne', 11: 'Automne'
            })
        
        print(f"‚úÖ Extraction termin√©e: {len(df)} observations")
        return df
        
    except Exception as e:
        print(f"‚ùå Erreur extraction: {e}")
        return pd.DataFrame()

# ================================================================================
# FONCTIONS DE LISSAGE
# ================================================================================

def smooth_timeseries(dates, values, method='rolling', window=30):
    """
    Applique diff√©rentes m√©thodes de lissage aux donn√©es
    
    Args:
        dates: Series pandas de dates
        values: Series pandas de valeurs
        method: 'rolling', 'savgol', 'spline'
        window: taille de la fen√™tre pour rolling et savgol
    
    Returns:
        Series pandas liss√©e
    """
    if method == 'rolling':
        return values.rolling(window=window, center=True, min_periods=1).mean()
    
    elif method == 'savgol':
        # Filtre Savitzky-Golay (pr√©serve mieux les pics)
        if len(values) > window:
            return pd.Series(savgol_filter(values, window, 3), index=values.index)
        else:
            return values
    
    elif method == 'spline':
        # Interpolation par spline cubique
        # Convertir dates en nombres pour l'interpolation
        x = pd.to_numeric(dates)
        x_norm = (x - x.min()) / (x.max() - x.min())  # Normaliser pour stabilit√©
        
        # Supprimer les NaN
        mask = ~np.isnan(values)
        if mask.sum() > 3:  # Besoin d'au moins 4 points
            spl = UnivariateSpline(x_norm[mask], values[mask], s=0.1)
            return pd.Series(spl(x_norm), index=values.index)
        else:
            return values
    
    return values

# ================================================================================
# VISUALISATION AM√âLIOR√âE
# ================================================================================

def plot_albedo_evolution_enhanced(df, title="", smoothing_method='rolling', save_path=None):
    """
    Graphique d'√©volution temporelle am√©lior√© avec style moderne
    """
    if df.empty:
        print("‚ùå Aucune donn√©e √† visualiser")
        return None
    
    # Style moderne
    plt.style.use('seaborn-v0_8-darkgrid')
    fig, ax = plt.subplots(figsize=(16, 8))
    
    # Couleurs personnalis√©es
    colors = {
        'raw': '#B0BEC5',      # Gris bleu clair
        'smooth_7d': '#2196F3', # Bleu
        'smooth_30d': '#F44336', # Rouge
        'fill': '#FFCDD2',      # Rouge tr√®s clair
        'grid': '#E0E0E0'       # Gris clair
    }
    
    # Trier les donn√©es
    df_sorted = df.sort_values('date').copy()
    
    # 1. Donn√©es brutes
    ax.scatter(df_sorted['date'], df_sorted['albedo_mean'], 
              alpha=0.2, s=8, color=colors['raw'], label='Donn√©es quotidiennes', 
              edgecolors='none', rasterized=True)
    
    # 2. Lissages
    smooth_7d = smooth_timeseries(df_sorted['date'], df_sorted['albedo_mean'], 
                                  method='rolling', window=7)
    smooth_30d = smooth_timeseries(df_sorted['date'], df_sorted['albedo_mean'], 
                                   method=smoothing_method, window=30)
    
    # Tracer les courbes
    ax.plot(df_sorted['date'], smooth_7d, 
           color=colors['smooth_7d'], linewidth=1.5, alpha=0.7, 
           label='Moyenne 7 jours')
    ax.plot(df_sorted['date'], smooth_30d, 
           color=colors['smooth_30d'], linewidth=3, 
           label=f'Tendance 30 jours ({smoothing_method})')
    
    # 3. Bande d'incertitude
    if 'albedo_stdDev' in df_sorted.columns:
        std_smooth = smooth_timeseries(df_sorted['date'], df_sorted['albedo_stdDev'], 
                                      method='rolling', window=30)
        ax.fill_between(df_sorted['date'], 
                       smooth_30d - std_smooth,
                       smooth_30d + std_smooth,
                       alpha=0.15, color=colors['smooth_30d'], 
                       label='Intervalle de confiance (¬±1œÉ)')
    
    # 4. Annotations pour les saisons
    years = df_sorted['year'].unique()
    for year in years:
        # Marquer le d√©but de chaque √©t√© (juin)
        summer_date = pd.Timestamp(f'{year}-06-01')
        if summer_date >= df_sorted['date'].min() and summer_date <= df_sorted['date'].max():
            ax.axvline(summer_date, color='orange', alpha=0.3, linestyle='--', linewidth=0.8)
            ax.text(summer_date, ax.get_ylim()[1]*0.98, '√ât√©', 
                   rotation=0, ha='center', va='top', fontsize=8, alpha=0.7)
    
    # 5. Marquer les ann√©es de feux majeurs
    fire_years = {
        2017: "Feux BC",
        2018: "Feux BC", 
        2019: "Feux AB",
        2020: "Feux CA/US",
        2023: "Feux record"
    }
    
    for year, label in fire_years.items():
        if year in years:
            # Zone ombr√©e pour l'ann√©e de feu
            year_start = pd.Timestamp(f'{year}-01-01')
            year_end = pd.Timestamp(f'{year}-12-31')
            ax.axvspan(year_start, year_end, alpha=0.1, color='red', zorder=0)
            # √âtiquette
            mid_year = pd.Timestamp(f'{year}-07-01')
            if mid_year >= df_sorted['date'].min() and mid_year <= df_sorted['date'].max():
                ax.text(mid_year, ax.get_ylim()[0] + 0.02, label, 
                       rotation=90, ha='center', va='bottom', fontsize=9, 
                       color='darkred', alpha=0.7)
    
    # 6. Statistiques dans le graphique
    mean_albedo = df_sorted['albedo_mean'].mean()
    ax.axhline(mean_albedo, color='black', linestyle=':', alpha=0.5, linewidth=1)
    ax.text(df_sorted['date'].iloc[-1], mean_albedo, f'  Moyenne: {mean_albedo:.3f}', 
           va='center', ha='left', fontsize=10)
    
    # 7. Tendance lin√©aire globale
    if len(df_sorted) > 10:
        x_numeric = pd.to_numeric(df_sorted['date']) / 1e11  # Normaliser pour la r√©gression
        z = np.polyfit(x_numeric, df_sorted['albedo_mean'], 1)
        p = np.poly1d(z)
        trend_line = p(x_numeric)
        ax.plot(df_sorted['date'], trend_line, 'k--', alpha=0.5, linewidth=2,
               label=f'Tendance: {z[0]*365.25/10:.4f}/an')
    
    # Mise en forme
    ax.set_xlabel('Date', fontsize=12, fontweight='bold')
    ax.set_ylabel('Alb√©do', fontsize=12, fontweight='bold')
    ax.set_title(f'√âvolution de l\'alb√©do du glacier Athabasca{title}', 
                fontsize=16, fontweight='bold', pad=20)
    
    # Limites et grille
    ax.set_ylim(bottom=0, top=max(df_sorted['albedo_mean'].max() * 1.1, 1.0))
    ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)
    
    # L√©gende
    ax.legend(loc='upper left', frameon=True, fancybox=True, 
             shadow=True, fontsize=10, ncol=2)
    
    # Format des dates sur l'axe X
    import matplotlib.dates as mdates
    ax.xaxis.set_major_locator(mdates.YearLocator())
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
    ax.xaxis.set_minor_locator(mdates.MonthLocator([4, 7, 10]))
    
    # Rotation des labels
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')
    
    # Ajustement final
    plt.tight_layout()
    
    # Sauvegarder si demand√©
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"üíæ Graphique sauvegard√©: {save_path}")
    
    plt.show()
    return fig

# ================================================================================
# VISUALISATION RAPIDE
# ================================================================================

def plot_albedo_fast(df, title_suffix="", smoothing_method='rolling'):
    """Graphiques simplifi√©s pour glacier entier"""
    if df.empty:
        print("‚ùå Aucune donn√©e √† visualiser")
        return None
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle(f'Glacier Athabasca - Analyse Alb√©do{title_suffix}', 
                 fontsize=14, fontweight='bold')
    
    # 1. S√©rie temporelle avec bande d'erreur et lissage
    # Trier les donn√©es par date
    df_sorted = df.sort_values('date').copy()
    
    # Donn√©es brutes en points transparents
    axes[0,0].scatter(df_sorted['date'], df_sorted['albedo_mean'], 
                     alpha=0.3, s=15, color='gray', label='Donn√©es brutes', zorder=1)
    
    # Appliquer diff√©rents lissages
    # Lissage court terme (7 jours)
    smooth_7d = smooth_timeseries(df_sorted['date'], df_sorted['albedo_mean'], 
                                  method='rolling', window=7)
    
    # Lissage moyen terme (30 jours) 
    smooth_30d = smooth_timeseries(df_sorted['date'], df_sorted['albedo_mean'], 
                                   method=smoothing_method, window=30)
    
    # Tracer les courbes liss√©es
    axes[0,0].plot(df_sorted['date'], smooth_7d, 
                  'b-', label='Moyenne mobile 7 jours', linewidth=1.2, alpha=0.7, zorder=2)
    axes[0,0].plot(df_sorted['date'], smooth_30d, 
                  'r-', label=f'Lissage 30 jours ({smoothing_method})', linewidth=2.5, zorder=3)
    
    # Bande d'incertitude liss√©e
    if 'albedo_stdDev' in df_sorted.columns:
        std_smooth = smooth_timeseries(df_sorted['date'], df_sorted['albedo_stdDev'], 
                                      method='rolling', window=30)
        axes[0,0].fill_between(df_sorted['date'], 
                             smooth_30d - std_smooth,
                             smooth_30d + std_smooth,
                             alpha=0.15, color='red', label='¬± 1 √©cart-type (liss√©)', zorder=0)
    
    # Mise en forme
    axes[0,0].set_title('√âvolution temporelle de l\'alb√©do', fontsize=12, fontweight='bold')
    axes[0,0].set_ylabel('Alb√©do', fontsize=11)
    axes[0,0].set_xlabel('Date', fontsize=11)
    axes[0,0].legend(loc='best', fontsize=9)
    axes[0,0].grid(True, alpha=0.3, linestyle='--')
    axes[0,0].set_ylim(bottom=0)  # L'alb√©do ne peut pas √™tre n√©gatif
    
    # 2. Tendances annuelles avec r√©gression
    annual_stats = df.groupby('year').agg({
        'albedo_mean': ['mean', 'std', 'count']
    }).reset_index()
    annual_stats.columns = ['year', 'mean', 'std', 'count']
    
    if len(annual_stats) > 1:
        axes[0,1].errorbar(annual_stats['year'], annual_stats['mean'], 
                          yerr=annual_stats['std'], fmt='bo-', capsize=5,
                          label='Moyenne annuelle ¬± √©cart-type')
        
        # Tendance lin√©aire
        if len(annual_stats) > 2:
            z = np.polyfit(annual_stats['year'], annual_stats['mean'], 1)
            p = np.poly1d(z)
            axes[0,1].plot(annual_stats['year'], p(annual_stats['year']), 'r--', 
                          alpha=0.7, label=f'Tendance: {z[0]:.4f}/an')
            
            # Calcul R¬≤
            yhat = p(annual_stats['year'])
            ybar = np.mean(annual_stats['mean'])
            ssreg = np.sum((yhat - ybar)**2)
            sstot = np.sum((annual_stats['mean'] - ybar)**2)
            r2 = ssreg / sstot if sstot > 0 else 0
            axes[0,1].text(0.05, 0.95, f'R¬≤ = {r2:.3f}', transform=axes[0,1].transAxes,
                          verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    axes[0,1].set_title('Moyennes annuelles et tendance')
    axes[0,1].set_xlabel('Ann√©e')
    axes[0,1].set_ylabel('Alb√©do moyen')
    axes[0,1].legend()
    axes[0,1].grid(True, alpha=0.3)
    
    # 3. Cycle saisonnier
    seasonal_stats = df.groupby('month').agg({
        'albedo_mean': ['mean', 'std', 'count']
    }).reset_index()
    
    months = ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Jun',
              'Jul', 'Ao√ª', 'Sep', 'Oct', 'Nov', 'D√©c']
    
    axes[1,0].errorbar(seasonal_stats['month'], 
                      seasonal_stats[('albedo_mean', 'mean')],
                      yerr=seasonal_stats[('albedo_mean', 'std')],
                      fmt='bo-', capsize=5, linewidth=2)
    axes[1,0].set_title('Cycle saisonnier moyen')
    axes[1,0].set_xlabel('Mois')
    axes[1,0].set_ylabel('Alb√©do')
    axes[1,0].set_xticks(range(1, 13))
    axes[1,0].set_xticklabels(months, rotation=45)
    axes[1,0].grid(True, alpha=0.3)
    
    # 4. Distribution par saison avec statistiques
    season_order = ['Hiver', 'Printemps', '√ât√©', 'Automne']
    df_season = df[df['season'].isin(season_order)]
    
    if not df_season.empty:
        box_plot = sns.boxplot(data=df_season, x='season', y='albedo_mean', 
                              order=season_order, ax=axes[1,1])
        
        # Ajouter les moyennes
        means = df_season.groupby('season')['albedo_mean'].mean()
        positions = range(len(season_order))
        for pos, season in enumerate(season_order):
            if season in means.index:
                axes[1,1].text(pos, means[season], f'{means[season]:.3f}', 
                             ha='center', va='bottom', fontsize=10)
        
        axes[1,1].set_title('Distribution saisonni√®re')
        axes[1,1].set_xlabel('Saison')
        axes[1,1].set_ylabel('Alb√©do')
    
    plt.tight_layout()
    plt.show()
    
    return fig

# ================================================================================
# FONCTION PRINCIPALE AVEC OPTIONS
# ================================================================================

def run_analysis_optimized(period='recent', sampling=None, scale=500, use_broadband=False, smoothing='rolling'):
    """
    Fonction principale avec options d'optimisation
    
    Args:
        period: 'recent', 'fire_years', 'decade', 'sample', ou tuple (start, end)
        sampling: None, 'weekly', 'monthly', 'seasonal'
        scale: 250, 500, 1000 (r√©solution en m√®tres)
        use_broadband: False (neige) ou True (large bande)
        smoothing: 'rolling', 'savgol', 'spline' (m√©thode de lissage)
    """
    
    print("üöÄ ANALYSE OPTIMIS√âE Alb√©do Glacier Athabasca")
    print("=" * 60)
    
    # D√©finir p√©riode
    if isinstance(period, tuple):
        start_date, end_date = period
        period_name = f"Personnalis√©e ({start_date} √† {end_date})"
    else:
        start_date, end_date = PERIODS_RAPIDE[period]
        period_name = period.title()
    
    # D√©finir √©chantillonnage
    sampling_days = SAMPLING_OPTIONS.get(sampling) if sampling else None
    
    print(f"üìÖ P√©riode: {period_name}")
    print(f"‚è±Ô∏è √âchantillonnage: {sampling or 'Toutes les images'}")
    print(f"üéØ R√©solution: {scale}m")
    print(f"üìä Type donn√©es: {'Large bande (MCD43A3 v6.1)' if use_broadband else 'Neige quotidien (MOD/MYD10A1 v6.1)'}")
    
    # Extraction
    df = extract_time_series_fast(
        start_date, end_date,
        use_broadband=use_broadband,
        sampling_days=sampling_days,
        scale=scale
    )
    
    if df.empty:
        print("‚ùå Aucune donn√©e extraite")
        return None
    
    # Statistiques rapides
    print(f"\nüìà R√âSULTATS:")
    print(f"   ‚Ä¢ {len(df)} observations")
    print(f"   ‚Ä¢ P√©riode effective: {df['date'].min()} √† {df['date'].max()}")
    
    if 'albedo_mean' in df.columns:
        albedo_data = df['albedo_mean'].dropna()
        if not albedo_data.empty:
            print(f"   ‚Ä¢ Alb√©do moyen du glacier: {albedo_data.mean():.3f} ¬± {albedo_data.std():.3f}")
            print(f"   ‚Ä¢ Plage de valeurs: [{albedo_data.min():.3f}, {albedo_data.max():.3f}]")
            print(f"   ‚Ä¢ Tendance annuelle: ", end="")
            
            annual_mean = df.groupby('year')['albedo_mean'].mean()
            if len(annual_mean) > 2:
                trend = np.polyfit(annual_mean.index, annual_mean.values, 1)[0]
                print(f"{trend:.4f}/an")
            else:
                print("Insuffisant pour calcul")
    
    # Visualisation
    print(f"\nüìä G√©n√©ration graphiques...")
    print(f"   ‚Ä¢ M√©thode de lissage: {smoothing}")
    
    # Graphiques standard
    plot_albedo_fast(df, f" - {period_name}", smoothing_method=smoothing)
    
    # Graphique d'√©volution am√©lior√©
    print(f"\nüìà G√©n√©ration graphique d'√©volution d√©taill√©...")
    plot_albedo_evolution_enhanced(df, f" ({period_name})", 
                                  smoothing_method=smoothing,
                                  save_path=f'evolution_albedo_{period}_{scale}m.png')
    
    # Export
    filename = f'athabasca_albedo_{period}_{scale}m.csv'
    df.to_csv(filename, index=False)
    print(f"üíæ Donn√©es export√©es: {filename}")
    
    return df

# ================================================================================
# EXEMPLES D'UTILISATION RAPIDE
# ================================================================================

if __name__ == "__main__":
    print("üéõÔ∏è OPTIONS D'ANALYSE RAPIDE:")
    print("\n1Ô∏è‚É£ ULTRA-RAPIDE (test): 5 ans r√©cents, r√©solution 1km")
    print("2Ô∏è‚É£ RAPIDE: Ann√©es feux, r√©solution 500m")  
    print("3Ô∏è‚É£ STANDARD: Derni√®re d√©cennie, r√©solution 500m")
    print("4Ô∏è‚É£ PERSONNALIS√â: Vos param√®tres")
    
    # Recommandation par d√©faut: P√©riode r√©cente √©tendue jusqu'√† automne 2024
    print(f"\nüéØ EX√âCUTION: Analyse r√©cente compl√®te (2019-Oct 2024)...")
    df_result = run_analysis_optimized(
        period='full_recent',   # 2019-2024 (automne)
        sampling=None,          # Toutes images disponibles
        scale=500,              # R√©solution MODIS standard
        use_broadband=False,    # Alb√©do neige quotidien
        smoothing='savgol'      # Lissage Savitzky-Golay pour pr√©server les d√©tails
    )
    
    print(f"\n‚úÖ ANALYSE TERMIN√âE!")
    print(f"üí° Pour d'autres options, modifiez les param√®tres de run_analysis_optimized()")
    
    # Exemples autres configurations:
    print(f"\nüîß AUTRES EXEMPLES:")
    print(f"# Ultra-rapide (test)")
    print(f"# run_analysis_optimized('recent', 'monthly', 1000)")
    print(f"")
    print(f"# P√©riode personnalis√©e")
    print(f"# run_analysis_optimized(('2018-01-01', '2020-12-31'), None, 500)")
    print(f"")
    print(f"# Alb√©do large bande")
    print(f"# run_analysis_optimized('decade', 'weekly', 500, use_broadband=True)")